
import utils.debug as debug
import clang.cindex
import ast_object.ast_utils as ast_utils
import code_object.arg as arg
import code_object.array_access as array_access
import code_object.binary_operation as binary_operation
import code_object.catch_statement as catch_statement
import code_object.case_statement as case_statement
import code_object.cast_expression as cast_expression
import code_object.code_objects as code_objects
import code_object.compound_statement as compound_statement
import code_object.conditional_operation as conditional_operation
import code_object.declaration_specifier as declaration_specifier
import code_object.for_statement as for_statement
import code_object.function_call as function_call
import code_object.goto_statement as goto_statement
import code_object.if_statement as if_statement
import code_object.init_list as init_list
import code_object.macro_definition as macro_definition
import code_object.macro_instantation as macro_instantation
import code_object.label_statement as label_statement
import code_object.literal as literal
import code_object.paren_expression as paren_expression
import code_object.return_statement as return_statement
import code_object.struct_member_access as struct_member_access
import code_object.switch_statement as switch_statement
import code_object.try_statement as try_statement
import code_object.try_block as try_block
import code_object.unary_expression as unary_expression
import code_object.unary_operation as unary_operation
import code_object.value_declaration_reference as value_declaration_reference
import code_object.variable_declaration as variable_declaration
import code_object.while_statement as while_statement
from code_object.code_interface import NONE_VALUE
from code_object_converter.conversion_utils import as_commented_out_code

# Parse AstCode and create code interface objects: classes that implement the CodeInterface
#
# These C code interface objects can then be fed into code interface converters to output C++ code
#
# The input C code is from AST nodes generated by Libclang
class AstParser:
    def __init__(self) -> None:
        pass
    
    def get_debug_string(self, code_obj):
        if code_obj:
            return f"{code_obj if type(code_obj) is str else code_obj.as_string()}"
        else:
            return "None"
    
    # Parse the AST and return a list of CodeInterface objects representing the C objects
    # CNode can be a single node or a list of nodes (for example, the global declaration is a list)
    # - A list will be treated as a single block of code
    def to_ccode_objects(self, cnode, macro_details):
        self._macro_details = macro_details

        debug.line("to_ccode_objects", f"[IN] ==========================================================================================")

        parsed_cnode = self.parse_ast_node(cnode)
        if not parsed_cnode:
            debug.line("to_ccode_objects", f"Code object is None for node spelling=[{cnode.spelling}] type=[{cnode.type.spelling}] kind=[{cnode.kind}]")

        debug.line("to_ccode_objects", f"[OUT] ==========================================================================================")

        return parsed_cnode

    # Main entry point to parse an AST node and return a CodeInterface objects
    #
    # Can be called recursively
    #
    # Note - Prefer to call this as it handles macro expansions
    def parse_ast_node(self, node):

        debug.line("parse_ast_node", f"[{node.kind}] spelling=[{node.spelling}] type=[{node.type.spelling}] extent={ast_utils.node_extent(node)}")

        # Handle macros
        macro_instantiation_node = self._macro_details.instantiation_node_for(node)
        if macro_instantiation_node:
            return self.parse_macro_instantiation(macro_instantiation_node, node)

        if node.kind.is_statement():
            return self.parse_STMT_node(node)
        elif node.kind.is_declaration():
            return self.parse_DECL_node(node)
        elif node.kind.is_expression():
            return self.parse_EXPR_node(node)
        elif node.kind.is_reference():
            return self.parse_REF_node(node)
        elif node.kind == clang.cindex.CursorKind.MACRO_DEFINITION:
            return self.parse_macro_definition(node)
        else:
            assert False, f"Unclassified kind=[{node.kind}] spelling=[{node.spelling}]"

        return None
    
    # Default behaviour for node kinds that we ignore
    def parse_node_ignored_kind(self, node):
        debug.line("parse_node_ignored_kind", f"*** IGNORING *** spelling=[{node.spelling}] kind=[{node.kind}]")
        '''if node.kind == clang.cindex.CursorKind.UNEXPOSED_DECL:
            debug.line("parse_node_ignored_kind", f"     Not dumping node - could be a lot of tokens if #include !")
        else:
            ast_utils.dump_node(node,5)'''

        return None

    # Placeholder for node kinds that we should support, but haven't yet implemented!
    def parse_node_not_implemented(self, node):
        debug.line("parse_node_not_implemented", f"*** kind=[{node.kind}] not implemented ***")
        #ast_utils.dump_node(node,5)
        debug.line("parse_node_not_implemented", f"No convert routine implemented for kind=[{node.kind}]")
        assert False, f"No convert routine implemented for kind=[{node.kind}]"
        return None

    # =================================== Macros Convert functions [BEGIN] ===================================

    def parse_macro_definition(self, node):
        debug.line("parse_macro_definition", f"MACRO spelling=[{node.spelling}] kind=[{node.kind}] extent={ast_utils.node_extent(node)}")
        tokens = [token.spelling for token in node.get_tokens()]
        debug.line("parse_macro_definition", f"MACRO tokens=[{tokens}]")
        tokens_count = len(tokens)
        assert tokens_count > 0, f"Expected at least 1 macro token!"

        macro_text = "#define " + tokens[0]

        # The tokens don't contain any whitespace, so ["FOO", "0"] could be
        # #define FOO0
        # #define FOO 0
        #
        # To try and mitigate this, we'll use the following rules:
        # 1. If the 2nd token is "(", assume function macro:  #define FOO(a) a*a
        # 2. If the 2nd token ISN'T "(", assume object macro: #define FOO BAR
        # 3. Add a space after every subsequent token
        #
        # Note: Use the debug output to confirm the converted macro
        if tokens_count > 1:
            if tokens[1] != "(":
                macro_text += " "
            macro_text += " ".join(tokens[1:])

        debug.line("parse_macro_definition", f"MACRO text=[{macro_text}]")
        macro_def = macro_definition.MacroDefinition()
        macro_def.add_line(macro_text)

        return macro_def


    def find_root_macro_node(self, node):
        for child in node.get_children():
            child_tokens = [token.spelling for token in child.get_tokens()]
            if len(child_tokens) > 0:
                return child

            node_with_tokens = self.find_root_macro_node(child)
            if node_with_tokens:
                return node_with_tokens

        return None

    # Attempt to match as many tokens as possible in the macro node hierarchy. 
    # The node with the highest number of matches will be selected
    # Returns the matched node (or None) and the number of tokens matched
    def match_tokens(self, tokens, node, match_count):
        new_tokens = [token.spelling for token in node.get_tokens()]
        tokens_count = len(tokens)
        new_node = None
        new_tokens_count = len(new_tokens)
        tokens_to_match = min(tokens_count, new_tokens_count)

        best_match_count = 0
        for i in range(tokens_to_match):
            if new_tokens[i] == tokens[i]:
                best_match_count += 1
            else:
                break

        if best_match_count > 0:
            new_node = node

        if best_match_count != tokens_count:
            for child in node.get_children():
                child_node, child_match_count = self.match_tokens(tokens, child, best_match_count)
                if child_match_count > best_match_count:
                    best_match_count = child_match_count
                    new_node = child_node
                    break

        if new_node:
            debug.line("match_tokens", f"new_node [{new_node.kind}] spelling=[{new_node.spelling}] best_match_count=[{best_match_count}]")

        return new_node, best_match_count

    # Convert all the tokens of the macro, either by finding the appropriate child node and parsing it (match_tokens function),
    # or creating a literal representation of the token.
    # Returns the code_object (or None) and remaining (unmatched) tokens
    def convert_tokens(self, tokens, root_expanded_node):
        debug.line("convert_tokens", f"[IN] tokens=[{tokens}] root_expanded_node kind={root_expanded_node.kind} spelling=[{root_expanded_node.spelling}]")

        matched_node, match_count = self.match_tokens(tokens, root_expanded_node, 0)
        if matched_node:
            converted_tokens = self.parse_ast_node(matched_node)
            debug.line("convert_tokens", f"     MATCH - converted_tokens=[{converted_tokens.as_string()}] tokens=[{tokens}] match_count=[{match_count}]")
            return converted_tokens, tokens[match_count:]
        else:
            converted_token = literal.Literal(tokens.pop(0))
            debug.line("convert_tokens", f"     NO MATCH - converted_token=[{converted_token.as_string()}] tokens=[{tokens}]")
            return converted_token, tokens


    # macro_node is the original macro code in the C file
    # expanded_node is the code after the pre-processor has applied the macro expansion
    def parse_macro_instantiation(self, macro_node, expanded_node):
        debug.line("parse_macro_instantiation", f"MACRO macro_node spelling=[{macro_node.spelling}] kind=[{macro_node.kind}] extent={ast_utils.node_extent(expanded_node)}")
        debug.line("parse_macro_instantiation", f"MACRO macro_node dump:")
        ast_utils.dump_node(macro_node, 2, "truncate")

        debug.line("parse_macro_instantiation", f"MACRO expanded_node spelling=[{expanded_node.spelling}] kind=[{expanded_node.kind}] extent={ast_utils.node_extent(expanded_node)}")
        debug.line("parse_macro_instantiation", f"MACRO expanded_node dump:")
        ast_utils.dump_node(expanded_node, 2, "truncate")

        macro_node_tokens = [token.spelling for token in macro_node.get_tokens()]

        root_expanded_node = self.find_root_macro_node(expanded_node)

        if not root_expanded_node:
            debug.line("parse_macro_instantiation", f"Could not find root_expanded_node, treating macro_node contents as a literal")
            return literal.Literal(f"{' '.join(t for t in macro_node_tokens)}")

        macro_name = macro_node_tokens.pop(0)
        macro_expression = code_objects.CodeObjects()
        debug.line("parse_macro_instantiation", f"Found root_expanded_node, kind=[{root_expanded_node.kind}], parsing...")

        if len(macro_node_tokens) > 0:
            # Remove the opening paren so it doesn't cause a double-parse of the top-level node (leading to odd results!)
            if macro_node_tokens[0] == "(":
                open_parens_literal = literal.Literal(macro_node_tokens.pop(0))
                macro_expression.add_code_object(open_parens_literal)

            while len(macro_node_tokens) > 0:
                converted_node, macro_node_tokens = self.convert_tokens(macro_node_tokens, root_expanded_node)
                debug.line("parse_macro_instantiation", f"converted_node=[{debug.as_debug_string(converted_node)}]")
                macro_expression.add_code_object(converted_node)

        macro_inst = macro_instantation.MacroInstantation(macro_name, macro_expression)
        debug.line("parse_macro_instantiation", f"FINAL MACRO INST=[{macro_inst.as_string()}]")
        return macro_inst

    # =================================== Macros Convert functions [END]   ===================================

    # =================================== parse_STMT_funcs [BEGIN] ===================================

    # Just iteratively call parse_ast_node
    def parse_COMPOUND_STMT(self, node):

        #debug.line("parse_COMPOUND_STMT", f"Dumping node for MACRO INFO:")
        #ast_utils.dump_node(node, 2)

        stmt_lines = compound_statement.CompoundStatement()

        for child in node.get_children():
            stmt_lines.add_code_object(self.parse_ast_node(child))

        return stmt_lines

    # DECL_STMT is an "Adaptor class for mixing declarations with statements and expressions."
    # For now we'll just call parse_ast_node recursively with the children...
    def parse_DECL_STMT(self, node):
        stmt_lines = code_objects.CodeObjects()

        for child in node.get_children():
            stmt_lines.add_code_object(self.parse_ast_node(child))

        return stmt_lines

    def parse_GOTO_STMT(self, node):
        children = list(node.get_children())
        child_count = len(children)
        assert child_count == 1, f"Expected one child for goto statement, not [{child_count}]"

        label = self.parse_ast_node(children[0])

        return goto_statement.GotoStatement(label)

    def parse_LABEL_STMT(self, node):
        children = list(node.get_children())
        child_count = len(children)
        assert child_count == 1, f"Expected one child for label statement, not [{child_count}]"

        label = literal.Literal(node.spelling)
        statement = self.parse_ast_node(children[0])

        label_stmt = label_statement.LabelStatement(label, statement)
        debug.line("parse_LABEL_STMT", f"label_stmt=[{debug.as_debug_string(label_stmt)}]")
        #ast_utils.dump_node(node)
        #assert False

        return label_stmt

    def parse_RETURN_STMT(self, node):
        children = list(node.get_children())
        child_count = len(children)

        if child_count == 0:
            # Empty return statement, i.e. return;
            return return_statement.ReturnStatement(literal.Literal(""))

        assert child_count == 1, f"Expected at most one child for return statement, not [{child_count}]"
        return_value = children[0]

        tokens = [token.spelling for token in node.get_tokens()]
        return_value_tokens = [token.spelling for token in return_value.get_tokens()]

        if len(return_value_tokens) == 0:
            # Probably a macro - return as literal
            debug.line("parse_RETURN_STMT", f"The return value has no tokens: using the top-level tokens=[{tokens[1:]}]")
            return_cvalue = literal.Literal(f"{' '.join(t for t in tokens[1:])}")
        else:
            return_cvalue = self.parse_ast_node(return_value)

        return_lines = return_statement.ReturnStatement(return_cvalue)

        return return_lines

    def parse_IF_STMT(self, node):
        children = list(node.get_children())
        child_count = len(children)
        assert child_count >= 2, f"Expected at least two children for if statement"

        if_expression = self.parse_ast_node(children[0])
        if_action = self.parse_ast_node(children[1])
        if_stmt = if_statement.IfStatement(if_expression, if_action)

        if child_count == 3:
            else_statement = self.parse_ast_node(children[2])
            if_stmt.add_else(else_statement)

        return if_stmt

    def parse_SWITCH_STMT(self, node):
        children = list(node.get_children())
        child_count = len(children)
        assert child_count == 2, f"Expected two children for switch statement"

        condition = self.parse_ast_node(children[0])
        statement = self.parse_ast_node(children[1])

        switch_stmt = switch_statement.SwitchStatement(condition, statement)
        return switch_stmt

    def parse_WHILE_STMT(self, node):
        children = list(node.get_children())
        child_count = len(children)
        assert child_count == 2, f"Expected two children for while statement, not [{child_count}]"

        while_expression = self.parse_ast_node(children[0])
        while_action = self.parse_ast_node(children[1])

        while_stmt = while_statement.WhileStatement(while_expression, while_action)
        return while_stmt

    def parse_CASE_STMT(self, node):
        # NOTE: The CASE_STMT only contains two nodes: the constant_expression and the next statement
        # Any other statements under this case statement are parsed elsewhere!
        children = list(node.get_children())
        child_count = len(children)

        if node.kind == clang.cindex.CursorKind.DEFAULT_STMT:
            assert child_count == 1, f"Expected one child for default statement"
            constant_expression = literal.Literal("default")
        else:
            assert child_count == 2, f"Expected two children for case statement"
            constant_expression = self.parse_ast_node(children[0])

        statement = self.parse_ast_node(children[-1])

        switch_stmt = case_statement.CaseStatement(constant_expression, statement)
        return switch_stmt

    def parse_BREAK_STMT(self, node):
        return literal.Literal("break;")

    def parse_CONTINUE_STMT(self, node):
        return literal.Literal("continue;")

    def parse_FOR_STMT(self, node):
        init_statement = condition = iteration_expression = statement = None

        # A for loop can have empty sections (e.g. for(i=0;;++i){} ) but we don't know which missing nodes
        # correspond with these, so need to identify them from the tokens...
        tokens = [token.spelling for token in node.get_tokens()]
            
        # Find the indices of the parens and semicolons in "for(;;)"
        loop_indices = [i for i, token in enumerate(tokens) if token in ['(',';',')']]
        
        # Check there are at least two semicolons as well as open/close parens
        assert len(loop_indices) >= 4, "Could not find 2 semicolons in for loop"

        open_paren_token_index = loop_indices[0]
        init_end_token_index = loop_indices[1]
        cond_end_token_index = loop_indices[2]
        close_paren_token_index = loop_indices[3]

        children = node.get_children()

        # init_statement
        if init_end_token_index-open_paren_token_index > 1:
            child = next(children, None)
            assert child, f"init_statement node=[None]: open_paren_token_index=[{open_paren_token_index}] init_end_token_index=[{init_end_token_index}]"
            init_statement = self.parse_ast_node(child)

        # condition
        if cond_end_token_index-init_end_token_index > 1:
            child = next(children, None)
            assert child, f"condition node=[None]: init_end_token_index=[{init_end_token_index}] cond_end_token_index=[{cond_end_token_index}]"
            condition = self.parse_ast_node(child)

        # iteration_expression
        if close_paren_token_index - cond_end_token_index > 1:
            child = next(children, None)
            assert child, f"iteration_expression node=[None]: cond_end_token_index=[{cond_end_token_index}] close_paren_token_index=[{close_paren_token_index}]"
            iteration_expression = self.parse_ast_node(child)

        # statement
        child = next(children, None)
        assert child, f"For loop has no statement! node=[None]"
        statement = self.parse_ast_node(child)

        for_stmt = for_statement.ForStatement(init_statement, condition, iteration_expression, statement)

        return for_stmt

    def parse_NULL_STMT(self, node):
        return literal.Literal(node.spelling)
    
    def parse_CXX_TRY_STMT(self, node):
        ctry_statement = None
        ccatch_statements = code_objects.CodeObjects()

        for child in node.get_children():
            if child.kind == clang.cindex.CursorKind.CXX_CATCH_STMT:
                ccatch_statement = self.parse_ast_node(child)
                assert ccatch_statement
                ccatch_statements.add_code_object(ccatch_statement)
            else:
                # Assume it's the try statement (so there shoulkd be only one non-catch node)
                assert ctry_statement is None, f"Unexpected additional try statement..."
                try_stmt = self.parse_ast_node(child)
                ctry_statement = try_statement.TryStatement(try_stmt)

        assert ctry_statement, f"Could not find Try statement!"

        return try_block.TryBlock(ctry_statement, ccatch_statements)

    def parse_CXX_CATCH_STMT(self, node):
        children = list(node.get_children())
        assert len(children) == 2, f"Expected two child nodes, got [{len(children)}]"

        expression = self.parse_ast_node(children[0])
        statement = self.parse_ast_node(children[1])
        return catch_statement.CatchStatement(expression, statement)

    parse_STMT_funcs = {
        clang.cindex.CursorKind.COMPOUND_STMT:  parse_COMPOUND_STMT,
        clang.cindex.CursorKind.DECL_STMT:      parse_DECL_STMT,
        clang.cindex.CursorKind.CASE_STMT:      parse_CASE_STMT,
        clang.cindex.CursorKind.DEFAULT_STMT:   parse_CASE_STMT,
        clang.cindex.CursorKind.IF_STMT:        parse_IF_STMT,
        clang.cindex.CursorKind.LABEL_STMT:     parse_LABEL_STMT,
        clang.cindex.CursorKind.SWITCH_STMT:    parse_SWITCH_STMT,
        clang.cindex.CursorKind.WHILE_STMT:     parse_WHILE_STMT,
        clang.cindex.CursorKind.DO_STMT:        parse_node_not_implemented,
        clang.cindex.CursorKind.FOR_STMT:       parse_FOR_STMT,
        clang.cindex.CursorKind.GOTO_STMT:      parse_GOTO_STMT,
        clang.cindex.CursorKind.CONTINUE_STMT:  parse_CONTINUE_STMT,
        clang.cindex.CursorKind.BREAK_STMT:     parse_BREAK_STMT,
        clang.cindex.CursorKind.RETURN_STMT:    parse_RETURN_STMT,
        clang.cindex.CursorKind.NULL_STMT:      parse_NULL_STMT,
        clang.cindex.CursorKind.CXX_TRY_STMT:   parse_CXX_TRY_STMT,
        clang.cindex.CursorKind.CXX_CATCH_STMT: parse_CXX_CATCH_STMT,
    }
    
    def parse_STMT_node(self, node):
        debug.line("parse_STMT_node", f"[IN] [{node.kind}] {' '.join([token.spelling for token in node.get_tokens()])}")
        parsed_node = self.parse_STMT_funcs[node.kind](self, node)
        debug.line("parse_STMT_node", f"[OUT][{type(parsed_node).__name__}] {self.get_debug_string(parsed_node)}")
        return parsed_node

    # =================================== parse_STMT_funcs [END]   ===================================

    # =================================== parse_DECL_funcs [BEGIN] ===================================

    # Assume this is just a declaration - the function body will be converted via a function class...
    def parse_FUNCTION_DECL(self, node):
        cfuncsig = ast_utils.create_cfuncsig(node)
        cfuncsig.is_declaration = True
        return cfuncsig

    # Similar to FUNCTION_DECL, we assume we only need to parse the function signature as the body will 
    # be converted via a function class
    def parse_FUNCTION_TEMPLATE(self, node):
        cfuncsig = ast_utils.create_template_cfuncsig(node)
        cfuncsig.is_declaration = True
        return cfuncsig

    def parse_STRUCT_DECL(self, node):
        cstruct_arg = ast_utils.create_cstruct_arg(node)
        return cstruct_arg

    def parse_PARM_DECL(self, node):
        return None

    def parse_TYPEDEF_DECL(self, node):
        typedef_type = node.underlying_typedef_type

        if typedef_type.kind == clang.cindex.TypeKind.POINTER:
            pointee = typedef_type.get_pointee()

            if pointee.kind == clang.cindex.TypeKind.FUNCTIONPROTO:
                # It's a function pointer
                cfuncsig_pointer = ast_utils.create_cfuncsig_pointer(node)
                return cfuncsig_pointer
            
        elif typedef_type.kind == clang.cindex.TypeKind.ELABORATED:
            # We don't need to process e.g. "typedef struct proj_mapping proj_mapping;" as C++ doesn't need it!
            pass

        return None

    def parse_FIELD_DECL(self, node):
        carg = ast_utils.create_carg(node)
        
        return carg

    def parse_VAR_DECL(self, node):
        cvariable = ast_utils.create_carg(node)
        cvalue = None

        children = list(node.get_children())
        child_count = len(children)
        assert child_count <= 3, f"Expected up to three children for variable declaration, got [{child_count}]"

        # Check if we have an assignment...
        tokens=[token.spelling for token in node.get_tokens()]
        if "=" in tokens:
            debug.line("parse_VAR_DECL", f"Assignment found [=] - parsing...")
            cvalue_node = children[-1]
            if cvalue_node.kind.is_expression():
                cvalue = self.parse_ast_node(cvalue_node)
            else:
                debug.line("parse_VAR_DECL", f"Ignoring cvalue_node spelling=[{cvalue_node.spelling}] type=[{cvalue_node.type.spelling}] kind=[{cvalue_node.kind}]")
        
        debug.line("parse_VAR_DECL", f"DEBUG: cvariable type=[{type(cvariable)}] as_string=[{debug.as_debug_string(cvariable)}]")
        debug.line("parse_VAR_DECL", f"DEBUG: cvalue    type=[{type(cvalue)}] as_string=[{debug.as_debug_string(cvalue)}]")

        if not cvalue:
            debug.line("parse_VAR_DECL", "No assigned value found, using default [{}]")
            cvalue = literal.Literal("{}")

        return variable_declaration.VariableDeclaration(cvariable, cvalue)

    # We need to do some specialist handling...
    def parse_UNEXPOSED_DECL(self, node):
        children = list(node.get_children())

        assert len(children) > 0, f"Expected at least one child node for UNEXPOSED_DECL"

        if node.type.spelling == "auto":
            # We assume this is a complex assignment e.g. auto [x,y] = foo();
            tokens = node.get_tokens()

            # [1] Find equals token and build up left operand of binary operation
            equals_token = None
            auto_string = ""
            for t in tokens:
                if t.spelling == "=":
                    equals_token = t
                    break
                else:
                    auto_string += t.spelling + " "

            assert equals_token
            left_operand = literal.Literal(auto_string)

            # [2] We assume the last child node is the right_operand
            right_operand = self.parse_ast_node(children[-1])

            auto_asignment = binary_operation.BinaryOperation(left_operand, "=", right_operand)

            debug.line("parse_UNEXPOSED_DECL", f"Created auto_assignment=[{debug.as_debug_string(auto_asignment)}]")

            return auto_asignment
        else:
            assert False, f"Don't know how to parse UNEXPOSED_DECL with type=[{node.type.spelling}]"

        return None

    def parse_STATIC_ASSERT(self, node):
        # static_assert isn't detected on some systems, so until this can be resolved we'll
        # just return the tokens as a literal string...
        assert False
        debug.line("parse_STATIC_ASSERT", f"***WARNING*** Proper conversion not yet supported for static_assert - using the raw tokens...")
        return literal.Literal(f"{' '.join(t.spelling for t in node.get_tokens())}")

    parse_DECL_funcs = {
        clang.cindex.CursorKind.FUNCTION_DECL:      parse_FUNCTION_DECL,
        clang.cindex.CursorKind.FUNCTION_TEMPLATE:  parse_FUNCTION_TEMPLATE,
        clang.cindex.CursorKind.STRUCT_DECL:        parse_STRUCT_DECL,
        clang.cindex.CursorKind.UNION_DECL:         parse_node_not_implemented,
        clang.cindex.CursorKind.FIELD_DECL:         parse_FIELD_DECL,
        clang.cindex.CursorKind.VAR_DECL:           parse_VAR_DECL,
        clang.cindex.CursorKind.PARM_DECL:          parse_PARM_DECL,
        clang.cindex.CursorKind.TYPEDEF_DECL:       parse_TYPEDEF_DECL,
        clang.cindex.CursorKind.TYPE_ALIAS_DECL:    parse_node_not_implemented,
        clang.cindex.CursorKind.UNEXPOSED_DECL:     parse_UNEXPOSED_DECL,
        clang.cindex.CursorKind.STATIC_ASSERT:      parse_STATIC_ASSERT,
    }

    def parse_DECL_node(self, node):
        debug.line("parse_DECL_node", f"[IN] [{node.kind}] {' '.join([token.spelling for token in node.get_tokens()])}")
        parsed_node = self.parse_DECL_funcs[node.kind](self, node)
        debug.line("parse_DECL_node", f"[OUT][{type(parsed_node).__name__}] {self.get_debug_string(parsed_node)}")
        return parsed_node

    # =================================== parse_DECL_funcs [END]   ===================================

    # =================================== parse_EXPR_funcs [BEGIN] ===================================

    # We just pass the request straight to the child...
    def parse_UNEXPOSED_EXPR(self, node):
        children = list(node.get_children())

        if len(children) == 0:
            value = " ".join([t.spelling for t in node.get_tokens()])
            debug.line("parse_UNEXPOSED_EXPR", f"No children, just returning tokens as literal=[{value}]")
            return literal.Literal(value)

        if children[0].kind == clang.cindex.CursorKind.DECL_REF_EXPR and \
           children[0].type.spelling == "<overloaded function type>":
            func_name = self.parse_ast_node(children[0])
            cargs = []
            for entry in children [1:]:
                carg = self.parse_ast_node(entry)
                cargs.append(carg)
                '''if entry.kind == clang.cindex.CursorKind.DECL_REF_EXPR:
                    carg = arg.Arg(entry.type.spelling, entry.spelling)
                    cargs.append(carg)'''
            func_call = function_call.FunctionCall(func_name.as_string(), cargs)
            debug.line("parse_UNEXPOSED_EXPR", f"Extracted func_call=[{debug.as_debug_string(func_call)}]")
            return func_call

        # Just parse the first child...
        return self.parse_ast_node(children[0])

    # This is a recursive convertion...
    def parse_INIT_LIST_EXPR(self, node):
        init_list_decl_spec = declaration_specifier.DeclSpec.from_decl_specifier_seq(node.type.spelling)
        cinit_list = init_list.InitList(init_list_decl_spec)

        for child in node.get_children():
            cvalue = self.parse_ast_node(child)
            if cvalue:
                cinit_list.add_entry(cvalue)

        return cinit_list

    def parse_INTEGER_LITERAL(self, node):
        if node.spelling:
            return literal.Literal(node.spelling)
        
        # We'll have to extract the value from the tokens
        tokens=[token.spelling for token in node.get_tokens()]
        if tokens:
            return literal.Literal(tokens[0])
        
        assert False, f"Could not extract integer literal"

    def parse_FLOATING_LITERAL(self, node):
        if node.spelling:
            return literal.Literal(node.spelling)
        
        # We'll have to extract the value from the tokens
        tokens=[token.spelling for token in node.get_tokens()]
        if tokens:
            return literal.Literal(tokens[0])
        
        assert False, f"Could not extract floating literal"

    def parse_STRING_LITERAL(self, node):
        return literal.Literal(node.spelling)

    def parse_CHARACTER_LITERAL(self, node):
        tokens = [token.spelling for token in node.get_tokens()]
        assert len(tokens) == 1, f"Expected one token for character literal, not [{len(tokens)}]"
        return literal.Literal(tokens[0])

    def parse_CXX_BOOL_LITERAL_EXPR(self, node):
        tokens = [token.spelling for token in node.get_tokens()]
        assert len(tokens) == 1, f"Expected one token for BOOL literal, not [{len(tokens)}]"
        return literal.Literal(tokens[0])

    def parse_PAREN_EXPR(self, node):

        children = list(node.get_children())
        assert len(children) == 1, f"Expected exactly one child for paren expression"
        expression = children[0]

        expression_value = self.parse_ast_node(expression)
        c_paren_expr = paren_expression.ParenExpression(expression_value)
        return c_paren_expr

    def parse_CXX_UNARY_EXPR(self, node):

        keyword = node.spelling
        if not keyword:
            # Some unary expressions (e.g. sizeof) give an empty keyword, but we can extract it
            # from the first token.
            tokens = [token.spelling for token in node.get_tokens()]
            keyword = tokens[0]
            assert keyword == "sizeof", f"Unexpected keyword [{keyword}] - not able to parse this (yet!)"

        children = list(node.get_children())
        child_count = len(children)

        if child_count == 0:
            # No child nodes so extract expression from tokens...
            expression_text = literal.Literal(" ".join([t for t in tokens[2:-1]]))
            expression = paren_expression.ParenExpression(expression_text)
        else:
            assert child_count == 1, f"Expected a maximum of one child for unary expression, got [{child_count}]"
            expression = self.parse_ast_node(children[0])
            if not isinstance(expression, paren_expression.ParenExpression):
                expression = paren_expression.ParenExpression(expression)

        c_unary_expr = unary_expression.UnaryExpression(keyword, expression)
        debug.line("parse_CXX_UNARY_EXPR", f"Created c_unary_expr=[{debug.as_debug_string(c_unary_expr)}]")
        return c_unary_expr

    def parse_UNARY_OPERATOR(self, node):
        children = list(node.get_children())
        assert len(children) == 1, f"Expected exactly one child for unary operator"
        operand = children[0]

        # Tokenize and find the operator
        tokens = [token.spelling for token in node.get_tokens()]
        tokens_count = len(tokens)
        operand_tokens = [token.spelling for token in operand.get_tokens()]
        operand_tokens_count = len(operand_tokens)

        if tokens_count != operand_tokens_count+1:
            # The top level tokens don't match the operand tokens. This will happen if the top-level
            # contains a macro definition. We should be able to handle this, so we'll just record the fact here!
            debug.line("parse_UNARY_OPERATOR", f"Expected tokens_count [{tokens_count}] to be 1 more than operand_tokens_count [{operand_tokens_count}]: assuming a macro")

        # Find the operator by eliminating the operand tokens
        # Need to determine if it is prefix or postfix operator
        if tokens[:operand_tokens_count] == operand_tokens[:operand_tokens_count]:
            op_value = tokens[-1]
            op_position = "postfix"
        else:
            op_value = tokens[0]
            op_position = "prefix"

        debug.line("parse_UNARY_OPERATOR", f"op_position=[{op_position}] op_value=[{op_value}]")

        operand_cvalue = self.parse_ast_node(operand)
        c_unary_op = unary_operation.UnaryOperation(op_value, operand_cvalue, op_position)

        return c_unary_op

    def parse_BINARY_OPERATOR(self, node):
        debug.line("parse_BINARY_OPERATOR", f"DEBUG NODE DUMP:")
        ast_utils.dump_node(node)

        children = list(node.get_children())
        assert len(children) == 2, f"Expected exactly two children for binary operator"

        left_operand, right_operand = children
        node_tokens = list(node.get_tokens())
        left_operand_tokens = list(left_operand.get_tokens())
        right_operand_tokens = list(right_operand.get_tokens())

        debug.line("parse_BINARY_OPERATOR", f"Node spelling=[{node.spelling}] tokens=[{[token.spelling for token in node_tokens]}] extent={ast_utils.node_extent(node)}")
        debug.line("parse_BINARY_OPERATOR", f"left_operand [{left_operand.kind}] spelling=[{left_operand.spelling}] tokens=[{[token.spelling for token in left_operand_tokens]}] type=[{left_operand.type.spelling}] extent={ast_utils.node_extent(left_operand)}")
        debug.line("parse_BINARY_OPERATOR", f"right_operand [{right_operand.kind}] spelling=[{right_operand.spelling}] tokens=[{[token.spelling for token in right_operand_tokens]}] type=[{right_operand.type.spelling}] extent={ast_utils.node_extent(right_operand)}")

        left_operand_cvalue = self.parse_ast_node(left_operand)
        right_operand_cvalue = self.parse_ast_node(right_operand)
        if not right_operand_cvalue:
            return literal.Literal(f"// [Ignoring C Code] {' '.join([token.spelling for token in node_tokens])}")

        debug.line("parse_BINARY_OPERATOR", f"left_operand_cvalue=[{debug.as_debug_string(left_operand_cvalue)}]")
        debug.line("parse_BINARY_OPERATOR", f"right_operand_cvalue=[{debug.as_debug_string(right_operand_cvalue)}]")

        # Get operator
        operator_token = None

        # Step 1: See if we have child node tokens
        node_tokens_count = len(node_tokens)
        left_tokens_count = len(left_operand_tokens)
        right_tokens_count = len(right_operand_tokens)

        if node_tokens_count > 0 and left_tokens_count > 0:
            if node_tokens_count >= left_tokens_count + right_tokens_count + 1:
                operator_token = node_tokens[left_tokens_count]

        debug.line("parse_BINARY_OPERATOR", f"[Step 1] [child tokens] node_tokens_count=[{node_tokens_count}] left_tokens_count=[{left_tokens_count}] right_tokens_count=[{right_tokens_count}]")
        debug.line("parse_BINARY_OPERATOR", f"[Step 1] [child tokens] operator_token=[{operator_token.spelling if operator_token else None}]")

        if not operator_token:
            # Step 2: Deduce it from the node tokens
            operator_source_range = clang.cindex.SourceRange.from_locations(left_operand.extent.end, right_operand.extent.start)
            debug.line("parse_BINARY_OPERATOR", f"operator_source_range=[{ast_utils.source_range_string(operator_source_range)}]")
            operator_token = ast_utils.find_token_from_source_range(node_tokens, operator_source_range)

        debug.line("parse_BINARY_OPERATOR", f"[Step 2] [node_tokens] operator_token=[{operator_token.spelling if operator_token else None}]")

        if not operator_token:
            # Step 3: Search ALL translation unit tokens (this will be slow for large C files - may need to optimise)
            operator_token = ast_utils.find_token_from_source_range(node.translation_unit.cursor.get_tokens(), operator_source_range)

        debug.line("parse_BINARY_OPERATOR", f"[Step 3] [ALL tokens] operator_token=[{operator_token.spelling if operator_token else None}]")
        assert operator_token

        c_binary_op = binary_operation.BinaryOperation(left_operand_cvalue, operator_token.spelling, right_operand_cvalue)
        return c_binary_op

    def parse_COMPOUND_ASSIGNMENT_OPERATOR(self, node):
        return self.parse_BINARY_OPERATOR(node)

    # This is usually a string representing a value, e.g. a variable name,
    # but can also represent an unresolved overloaded function set
    def parse_DECL_REF_EXPR(self, node):
        if node.type.spelling == "<overloaded function type>":
            return literal.Literal("".join([token.spelling for token in node.get_tokens()]))
        
        return value_declaration_reference.ValueDeclarationReference(node.spelling)


    # The top-level node contains the tokens showing the access, e.g. [['self', '->', 'grid_type']]
    # The child node defines the first parameter ("self" in this case)
    # However, as we're just storing strings, we'll use the tokens directly!
    def parse_MEMBER_REF_EXPR(self, node):

        tokens = [token.spelling for token in node.get_tokens()]
        debug.line("parse_MEMBER_REF_EXPR", f"[IN]  node spelling=[{node.spelling}] type=[{node.type.spelling}] tokens=[{tokens}]")
        assert len(tokens) >= 3, f"Expected at least 3 tokens for member ref, but got [{len(tokens)}]"

        cstruct_member_access = ast_utils.create_struct_member_access_from_tokens(tokens)

        debug.line("parse_MEMBER_REF_EXPR", f"[OUT] cstruct_member_access=[{debug.as_debug_string(cstruct_member_access)}]")

        return cstruct_member_access

    def parse_CALL_EXPR(self, node):
        tokens = [token.spelling for token in node.get_tokens()]

        if "(" in tokens:
            # NOTE: The function call may be in a struct, so we need to extract it correctly!
            children = node.get_children()
            child = next(children, None)
            assert child, f"Expected a child node while parsing a non-regular function call!"

            cfunc_name = self.parse_ast_node(child)
            debug.line("parse_CALL_EXPR", f"cfunc_name=[{cfunc_name.as_string()}] type=[{type(cfunc_name)}]")

            # TODO: Consider changing the object to StructMemberAccess if the func name needs to be updated?
            cfunc_call = function_call.FunctionCall(cfunc_name.as_string())

            for arg_node in node.get_arguments():
                arg_entry = self.parse_ast_node(arg_node)
                if arg_entry:
                    cfunc_call.add_arg(arg_entry)
                else:
                    debug.line("parse_CALL_EXPR", f"arg_node arg_entry=[{arg_entry}] - IS THIS AN ERROR?")

            return cfunc_call
        
        # No "(" in the tokens, so this is not really a function call!
        # It is probably a copy constructor, so we'll parse and return the (first) child node as whatever type it is...
        children = node.get_children()
        child = next(children, None)
        assert child, f"Expected a child node while parsing a non-regular function call!"

        return self.parse_ast_node(child)


    def parse_CSTYLE_CAST_EXPR(self, node):
        tokens = [token.spelling for token in node.get_tokens()]
        assert tokens[0] == "("

        # Extract the cast value by finding the first ')' [note this will throw if not found!]
        cast_value_end_index = tokens.index(")")

        ccast_value = literal.Literal(f"{' '.join([t for t in tokens[1:cast_value_end_index]])}")

        children = list(node.get_children())
        child_count = len(children)
        if child_count != 1:
            debug.line("parse_CSTYLE_CAST_EXPR", f"Expected exactly one child node for cast expression, but got [{child_count}] - we'll process the last node as the expression")

        cexpression = self.parse_ast_node(children[-1])

        ccast_expression = cast_expression.CastExpression("C", ccast_value, cexpression)

        debug.line("parse_CSTYLE_CAST_EXPR", f"Created ccast_expression = [{debug.as_debug_string(ccast_expression)}]")
        return ccast_expression

    def parse_CXX_CAST_EXPR(self, node):
        children = list(node.get_children())
        child_count = len(children)

        assert child_count >= 1, f"Expected at least one child for reinterpret_cast, got [{child_count}]"

        if node.kind == clang.cindex.CursorKind.CXX_REINTERPRET_CAST_EXPR:
            cxx_cast_type = "reinterpret"
        elif node.kind == clang.cindex.CursorKind.CXX_STATIC_CAST_EXPR:
            cxx_cast_type = "static"
        else:
            assert False, f"Unrecognized C++ cast type: kind=[{node.kind}]"

        # Extract the cast value by finding the first '<' and '>' [note this will throw if not found!]
        tokens = [token.spelling for token in node.get_tokens()]
        cast_start_index = tokens.index("<") + 1
        cast_end_index = tokens.index(">")
        cxx_cast_value = literal.Literal(f"{' '.join([t for t in tokens[cast_start_index:cast_end_index]])}")

        cxx_expression = self.parse_ast_node(children[-1])
        cxx_cast_expression = cast_expression.CastExpression(cxx_cast_type, cxx_cast_value, cxx_expression)

        debug.line("parse_CXX_REINTERPRET_CAST_EXPR", f"Created cxx_cast_expression = [{debug.as_debug_string(cxx_cast_expression)}]")
        return cxx_cast_expression

    def parse_ARRAY_SUBSCRIPT_EXPR(self, node):
        # We expect two children: the variable name and the index
        children = list(node.get_children())
        child_count = len(children)
        assert child_count == 2, f"Expected exactly two children for array subscription"

        name = self.parse_ast_node(children[0])
        index = self.parse_ast_node(children[1])

        if isinstance(name, struct_member_access.StructMemberAccess):
            debug.line("parse_ARRAY_SUBSCRIPT_EXPR", f"[FOR INFO] Array name is StructMemberAccess [{debug.as_debug_string(name)}]")

        arr_access = array_access.ArrayAccess(name, index)

        return arr_access

    def parse_CONDITIONAL_OPERATOR(self, node):
        # We expect three children: the condition, true branch and false branch
        children = list(node.get_children())
        child_count = len(children)
        assert child_count == 3, f"Expected exactly three children for conditional operator"

        bool_expression = self.parse_ast_node(children[0])
        true_expression = self.parse_ast_node(children[1])
        false_expression = self.parse_ast_node(children[2])

        cond_operation = conditional_operation.ConditionalOperation(bool_expression, true_expression, false_expression)

        return cond_operation

    parse_EXPR_funcs = {
        clang.cindex.CursorKind.UNEXPOSED_EXPR:                 parse_UNEXPOSED_EXPR,
        clang.cindex.CursorKind.DECL_REF_EXPR:                  parse_DECL_REF_EXPR,
        clang.cindex.CursorKind.MEMBER_REF_EXPR:                parse_MEMBER_REF_EXPR,
        clang.cindex.CursorKind.CALL_EXPR:                      parse_CALL_EXPR,
        clang.cindex.CursorKind.ARRAY_SUBSCRIPT_EXPR:           parse_ARRAY_SUBSCRIPT_EXPR,
        clang.cindex.CursorKind.CSTYLE_CAST_EXPR:               parse_CSTYLE_CAST_EXPR,
        clang.cindex.CursorKind.CXX_REINTERPRET_CAST_EXPR:      parse_CXX_CAST_EXPR,
        clang.cindex.CursorKind.CXX_STATIC_CAST_EXPR:           parse_CXX_CAST_EXPR,
        clang.cindex.CursorKind.COMPOUND_LITERAL_EXPR:          parse_node_not_implemented,
        clang.cindex.CursorKind.INIT_LIST_EXPR:                 parse_INIT_LIST_EXPR,
        clang.cindex.CursorKind.INTEGER_LITERAL:                parse_INTEGER_LITERAL,
        clang.cindex.CursorKind.FLOATING_LITERAL:               parse_FLOATING_LITERAL,
        clang.cindex.CursorKind.STRING_LITERAL:                 parse_STRING_LITERAL,
        clang.cindex.CursorKind.CHARACTER_LITERAL:              parse_CHARACTER_LITERAL,
        clang.cindex.CursorKind.PAREN_EXPR:                     parse_PAREN_EXPR,
        clang.cindex.CursorKind.CXX_UNARY_EXPR:                 parse_CXX_UNARY_EXPR,
        clang.cindex.CursorKind.UNARY_OPERATOR:                 parse_UNARY_OPERATOR,
        clang.cindex.CursorKind.BINARY_OPERATOR:                parse_BINARY_OPERATOR,
        clang.cindex.CursorKind.COMPOUND_ASSIGNMENT_OPERATOR:   parse_COMPOUND_ASSIGNMENT_OPERATOR,
        clang.cindex.CursorKind.CONDITIONAL_OPERATOR:           parse_CONDITIONAL_OPERATOR,
        clang.cindex.CursorKind.CXX_BOOL_LITERAL_EXPR:          parse_CXX_BOOL_LITERAL_EXPR,
    }

    def parse_EXPR_node(self, node):
        debug.line("parse_EXPR_node", f"[IN] [{node.kind}] {' '.join([token.spelling for token in node.get_tokens()])}")
        parsed_node = self.parse_EXPR_funcs[node.kind](self, node)
        debug.line("parse_EXPR_node", f"[OUT][{type(parsed_node).__name__}] {self.get_debug_string(parsed_node)}")
        return parsed_node

    # =================================== parse_EXPR_funcs [END]   ===================================

    # =================================== parse_REF_funcs [BEGIN]  ===================================

    def parse_TYPE_REF(self, node):
        return literal.Literal(node.spelling)

    def parse_NAMESPACE_REF(self, node):
        debug.line("parse_NAMESPACE_REF", f"NODES:")
        ast_utils.dump_node(node)
        return literal.Literal("::".join([t.spelling for t in node.get_tokens()]))

    def parse_LABEL_REF(self, node):
        return literal.Literal(node.spelling)

    parse_REF_funcs = {
        clang.cindex.CursorKind.TYPE_REF:       parse_TYPE_REF,
        clang.cindex.CursorKind.TEMPLATE_REF:   parse_node_not_implemented,
        clang.cindex.CursorKind.MEMBER_REF:     parse_node_not_implemented,
        clang.cindex.CursorKind.NAMESPACE_REF:  parse_NAMESPACE_REF,
        clang.cindex.CursorKind.LABEL_REF:      parse_LABEL_REF,
    }

    def parse_REF_node(self, node):
        debug.line("parse_REF_node", f"[IN] [{node.kind}] {' '.join([token.spelling for token in node.get_tokens()])}")
        parsed_node = self.parse_REF_funcs[node.kind](self, node)
        debug.line("parse_REF_node", f"[OUT][{type(parsed_node).__name__}] {self.get_debug_string(parsed_node)}")
        return parsed_node

    # =================================== parse_REF_funcs [END]    ===================================

